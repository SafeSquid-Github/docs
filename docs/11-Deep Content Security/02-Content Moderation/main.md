---
title: Content Moderation
---
SafeSquidâ€™s content moderation engine analyzes and filters web content in real-time to enforce compliance, safety, and productivity policies.

## Included Modules

- [Image Analyzer](/docs/11-Deep%20Content%20Security/02-Content%20Moderation/Image%20Analzer.md): Detects inappropriate or non-compliant visual content using AI-powered image analysis.
- [Text Analyzer](/docs/11-Deep%20Content%20Security/02-Content%20Moderation/Text%20Analyzer.md): Scans and classifies textual content for profanity, hate speech, and policy violations.

Use these tools to build a safer and policy-compliant browsing environment.
